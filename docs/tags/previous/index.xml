<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Previous on Yu&#39;s personal website</title>
    <link>https://moonblvd.github.io/brianyao_hugo/tags/previous/</link>
    <description>Recent content in Previous on Yu&#39;s personal website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2016 Your Name</copyright>
    <lastBuildDate>Sun, 17 Sep 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/brianyao_hugo/tags/previous/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Smart Black Box</title>
      <link>https://moonblvd.github.io/brianyao_hugo/project/smart-black-box/</link>
      <pubDate>Sun, 17 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://moonblvd.github.io/brianyao_hugo/project/smart-black-box/</guid>
      <description>&lt;p&gt;We are proposing the pipeline of a value-driven evernt data recorder for advanced and autonomous vehicles, called the Smart Black Box.&lt;/p&gt;

&lt;p&gt;The system captures raw data from on-board sensors (high-bandwidth sources such as cameras and LiDARs and low-bandwidth sources such as CAN Bus). The data is processs by some event detectors and the data value is computed from the information contect of the event. A deterministic Mealy machine is applied to determine when to start and stop buffering data according to data value, data similarity, and buffer size limitation. Each data buffer is compressed using a compression factor computed from a local buffer optimization (LBO) process. The LBO optimizes the trade-off between data value and storage cost.&lt;/p&gt;

&lt;p&gt;We evaluate the reproducibility of the Smart Black Box compressed data by applying them to computer vision tasks such as object detection and semantic segmentation. The result shows that the Smart Black Box records data with less than 10% of the original storage cost while the object detection and semantic segmentation tasks could still achieve over 90% mAPs.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Variable Autonomy SUAS For NAS Integration</title>
      <link>https://moonblvd.github.io/brianyao_hugo/project/nasa-airplane/</link>
      <pubDate>Wed, 14 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://moonblvd.github.io/brianyao_hugo/project/nasa-airplane/</guid>
      <description>&lt;p&gt;The overall project goal was to identify and track another small UAS that sporadically flew into andacross  the  field  of  view.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Human Activity Recognition based on Recurrent Neural Network</title>
      <link>https://moonblvd.github.io/brianyao_hugo/project/lstm/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://moonblvd.github.io/brianyao_hugo/project/lstm/</guid>
      <description>&lt;p&gt;Human activity recognition uses heterogeneous sensors to capture the state of user and environment. This has wide use in heath-related application such as health monitoring and athlete training. This project proposes a promising human activity recognition approach based on long-short term memory (LSTM) method using the smartphone inertial sensor data. Different kinds of network configuration are tested and explored in our experiment. A comparison with traditional machine learning method is also given in this paper.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>RGBD SLAM</title>
      <link>https://moonblvd.github.io/brianyao_hugo/project/rgbd-slam/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      
      <guid>https://moonblvd.github.io/brianyao_hugo/project/rgbd-slam/</guid>
      <description>&lt;p&gt;We build a simultaneous localization and mapping (SLAM) system  based on Microsoft Kinect 2 and Robot Operating System (ROS). Our system can estimate the trajectory of a hand held Kinect and generate the point cloud or octomap with color information of the environment. We present our approaches and system architecture in this paper and evaluate its performance through some published datasets as well as data from Kinect. The experiments demonstrate that our system is robust under slow sensor motion and relatively simple environment.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
